# Honeywell Forge Cognition - Runtime Configuration
# This file is mounted into the inference container

# Model Configuration
model_name: "maintenance-assist"

# Session Limits (adjust based on hardware)
# RTX 4000 Pro: 5-8 sessions
# Jetson Thor: 15-20 sessions
max_concurrent_sessions: 10

# Generation Parameters
max_tokens: 512
temperature: 0.7

# Performance Thresholds
gpu_memory_threshold: 0.85  # Alert if GPU memory > 85%
target_ttft_ms: 100.0       # Target time to first token (P90)
target_tps: 50.0            # Target output tokens per second
